{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQFLVOSbWsRMfTLys6zmIh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tolulope-Akinmoju/AdventureWorks-PowerBI-Sales-Dashboard/blob/main/HR_AdvML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afuZPINS9F1t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "import patsy\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VCpZznzmi8MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##Import Data\n",
        "data= \"/content/ClickedMSHR_MachineLearning.csv\"\n",
        "#column_names = ['Age', 'Attrition', 'BusinessTravel', 'Department', 'DistanceFromHome', 'Education',\n",
        "     #'EducationField' , 'EmployeeCount', 'EmployeeID', 'Gender', 'JobLevel', 'JobRole', 'MaritalStatus',\n",
        "    # 'MonthlyIncome', 'NumCompaniesWorked', 'Over18', 'PercentSalaryHike', 'StandardHours',\n",
        "     #'StockOptionLevel','TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany', 'YearsSinceLastPromotion',\n",
        "    # 'YearsWithCurrManager']#\n",
        "raw_dataset = pd.read_csv(data)"
      ],
      "metadata": {
        "id": "E_a0bAGZn_0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset =raw_dataset.copy()\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "NVd5k0ShnzWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KWQ12icUpSz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for NA Values ad Dtrop if Need Be\n"
      ],
      "metadata": {
        "id": "XEb-eepipplx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVYuqUvcp2WT",
        "outputId": "6123fb40-15d9-475b-bfa9-87ecacd96e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                         0\n",
              "Attrition                   0\n",
              "BusinessTravel              0\n",
              "Department                  0\n",
              "DistanceFromHome            0\n",
              "Education                   0\n",
              "EducationField              0\n",
              "EmployeeCount               0\n",
              "EmployeeID                  0\n",
              "Gender                      0\n",
              "JobLevel                    0\n",
              "JobRole                     0\n",
              "MaritalStatus               0\n",
              "MonthlyIncome               0\n",
              "NumCompaniesWorked         19\n",
              "Over18                      0\n",
              "PercentSalaryHike           0\n",
              "StandardHours               0\n",
              "StockOptionLevel            0\n",
              "TotalWorkingYears           9\n",
              "TrainingTimesLastYear       0\n",
              "YearsAtCompany              0\n",
              "YearsSinceLastPromotion     0\n",
              "YearsWithCurrManager        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.dropna()"
      ],
      "metadata": {
        "id": "JApBjEpFp-X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One hot encoding"
      ],
      "metadata": {
        "id": "qR13xri1qmdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#binary encoding\n",
        "dataset['Overtime'] = dataset['Overtime'].map(['No' : 0, 'Yes' :1})\n",
        "dataset['Gender'] = dataset['Gender'].map(['Male' : 0, 'Female' :1})\n",
        "dataset['Over18'] = dataset['Over18'].map(['No' : 0, 'Y' :1}"
      ],
      "metadata": {
        "id": "E4Aky-uHcVid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encode categorical columns which are ordinal\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoding_cols = ['BusinessTravel', 'Department', 'EducationField', 'JobRole', 'MaritalStatus']\n",
        "label_encoders = {}\n",
        "for column i encoding_cols:\n",
        "  label_encoders[column] = LabelEncoder()\n",
        "  dataset[column] = label_encoders[column]. fit_transform(dataset[column])"
      ],
      "metadata": {
        "id": "2piYuGjYjzeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = head()"
      ],
      "metadata": {
        "id": "uKEBqjselTir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create category maps\n",
        "\n",
        "dataset['Education'] = dataset['Education'].map({1: 'Below College', 2: 'College', 3: 'Bachelor', 4: 'Master', 5: 'Doctor'})\n",
        "dataset['JobLevel'] = dataset['JobLevel'].map({1: 'Entry', 2: 'Mid', 3: 'Senior', 4: 'Expert', 5: 'Executive'})\n",
        "dataset['StockOptionLevel'] = dataset['StockOptionLevel'].map({0: 'Low', 1: 'Medium', 2: 'High', 3: 'Very High'})"
      ],
      "metadata": {
        "id": "ZXwj6ZHsqp2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Onehot encode variables\n",
        "dataset = pd.get_dummies(dataset, columns= ['Education', 'JobLevel', 'StockOptionLevel'], prefix='', prefix_sep= '')"
      ],
      "metadata": {
        "id": "C-vuKI6V0fag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Onehot encode variables\n",
        "dataset = pd.get_dummies(dataset, columns= ['Attrition'], prefix='', prefix_sep= '')"
      ],
      "metadata": {
        "id": "Xiz42tE4sYHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Training and Test Dataset"
      ],
      "metadata": {
        "id": "1fjTVSfFsdfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.copy\n",
        "train_dataset = train_dataset()\n",
        "test_dataset = dataset.copy\n",
        "test_dataset = test_dataset()\n"
      ],
      "metadata": {
        "id": "akIhmIpMsepv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect data\n"
      ],
      "metadata": {
        "id": "jIjzGdXiskwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for non-numerical information and convert categorical data\n",
        "check_non_numerical_columns = [train_dataset, test_dataset]\n",
        "def check_non_numerical_columns(datasets):\n",
        "        for dataset in datasets:\n",
        "          for column in dataset.columns:\n",
        "            if train_dataset[column].dtype == 'object':\n",
        "              print(f\"Non-numerical data found in column: {column}\")\n",
        "              print(train_dataset[column].unique()) # Added and will test\n",
        "              print()"
      ],
      "metadata": {
        "id": "Gmnh2JkPslu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "KZeQCHN9shwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MonthlyIncome and ANOVA\n"
      ],
      "metadata": {
        "id": "ZIYo1Rmds84D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create train_anova dataset to ensure data integrity\n",
        "def train_anova(train_dataset):\n",
        "    anova_data = train_dataset[['MonthlyIncome', 'Attrition']].copy()\n",
        "    return anova_data\n",
        "\n",
        "anova_data = train_anova(train_dataset)"
      ],
      "metadata": {
        "id": "e2zXAUxdsqwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit an ANOVA model to determine if strong relationship exist btw MonthlyIncome and Attrition\n",
        "anova_data = train_anova(train_dataset)\n",
        "anova_model = ols('Attrition ~ M(MonthlyIncome)', data = anova_data).fit()\n",
        "anova_table = sm.stats.anova_lm(anova_model, typ=1)\n",
        "\n",
        "#Print the ANOVA table\n",
        "print(anova_table)\n",
        "\n",
        "#Drop MonthlyIncome from datasets\n",
        "train_dataset = train_dataset.drop(columns = ['MonthlyIncome'])\n",
        "test_dataset = test_dataset.drop(columns=['MonthlyIncome'])"
      ],
      "metadata": {
        "id": "D5mpps6BtX7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Decision Tree and Logistic Regression"
      ],
      "metadata": {
        "id": "fHYbWDzkvUlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess data\n",
        "X=train_dataset.drop('Age', axis =1)\n",
        "y= train_dataset['Age']\n",
        "\n",
        "#Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state =42)"
      ],
      "metadata": {
        "id": "Lj1WFklBvZv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create and Train Tree\n",
        "clf = DecisionTreeClassifier(max_depth =4) #Customize parameters later (e.g., max_depth)\n",
        "clf = clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "2EDeiJPjyFFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize results\n",
        "plt.figure(figure =(20,10)) #Adjust figsize if needed\n",
        "tree.plot_tree(clf, feature_names= X_train.columns, filled = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dm5K3El7yazl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}